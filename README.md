# Muesli

![Muesli GUI](docs/muesli.png)

Offline-first, privacy-centric voice **transcription** and **summarisation** desktop application powered by  
[whisper.cpp](https://github.com/ggerganov/whisper.cpp) and a local LLM served by [Ollama](https://ollama.ai/).

---

## Features

- ğŸ™ï¸ Microphone transcription with whisper.cpp
- ğŸ“‚ â€œOpen Fileâ€ transcription for WAV / MP3 / M4A / FLAC / OGG
- ğŸ§  Local LLM summarisation â€“ generated automatically right after transcription
- ğŸ“ Single combined markdown view
- ğŸ’¾ Save combined content as **.md**, **.txt**, or **.srt** (auto-generated block)
- ğŸŒ— Dark / Light / System theme
- ğŸ’» Runs completely offline

---

## Project Structure

```
muesli/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ LICENSE
â”œâ”€â”€ main.py
â”œâ”€â”€ models
â”œâ”€â”€ models.py
â”œâ”€â”€ Muesli.spec
â”œâ”€â”€ muesli.yaml.example
â”œâ”€â”€ ollama_client.py
â”œâ”€â”€ prompt.md
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ scripts
â”‚   â””â”€â”€ bootstrap_muesli_mac.sh
â”œâ”€â”€ stream_processor.py
â”œâ”€â”€ summarizer.py
â”œâ”€â”€ ui
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ compile_resources.py
â”‚   â”œâ”€â”€ main_window.py
â”‚   â”œâ”€â”€ qml
â”‚   â”‚   â””â”€â”€ main.qml
â”‚   â”œâ”€â”€ resources
â”‚   â”‚   â””â”€â”€ loading.svg
â”‚   â”œâ”€â”€ resources_rc.py
â”‚   â””â”€â”€ resources.qrc
â””â”€â”€ whisper_wrapper.py
```

---

## Requirements

| Requirement            | Purpose                      |
| ---------------------- | ---------------------------- |
| Python **3.8 +**       | Core application             |
| `whisper.cpp` binary   | On-device speech-to-text     |
| `ffmpeg` (recommended) | Decode/convert non-WAV audio |
| Ollama (optional)      | Local LLM for summaries      |

Python deps are listed in `requirements.txt`

---

## Installation

> [!WARNING]  
> This downloads ~12 GB worth of files, mostly taken up by llama 8b and whisper medium. It also spews stuff across your file system in unexpected ways. Check the script before running.

```bash
git clone https://github.com/JBlitzar/muesli
bash scripts/bootstrap_muesli_mac.sh
uv sync
```

### 4. Run

```bash
python main.py
```

---

## Usage

### Graphical UI

1. Start `muesli` (`python main.py`)
2. Click **Open File** _or_ **Record**
3. When you stop recording (or when file transcription ends) a summary is generated automatically and shown above the transcript.
4. Save the combined markdown via **File â†’ Save Contentâ€¦**

---

## Component Details

| Component                                                | Notes                                                                                                    |
| -------------------------------------------------------- | -------------------------------------------------------------------------------------------------------- |
| **WhisperTranscriber** (`whisper_wrapper.py`)            | Spawns whisper.cpp via `subprocess`, streams progress, verifies model checksum.                          |
| **TranscriptionStreamProcessor** (`stream_processor.py`) | Captures microphone audio with PyAudio, performs VAD, chunks audio into ~5 s segments, feeds to Whisper. |
| **OllamaClient** (`ollama_client.py`)                    | Thin subprocess wrapper around the `ollama run` CLI (no HTTP), supports streaming responses.             |
| **TranscriptSummarizer** (`summarizer.py`)               | Builds prompt templates and calls `OllamaClient` to get summary.                                         |
| **MuesliApp** (`main.py`)                                | Loads config, sets up components, exposes Qt signals for UI.                                             |
| **UI** (`ui/`)                                           | PySide6 widgets + optional QML; auto-updates via Qt signals.                                             |

---

## Development

```bash
git clone https://github.com/JBlitzar/muesli
bash scripts/bootstrap_muesli_mac.sh
black .       # format
isort .       # import order
ruff format . # format, again
```

---

## Troubleshooting

_Haha, good luck. This project is kind of a mess. But check the traceback. It's pretty well structured. If it is reproducable and would be helpful, feel free to leave an issue and I'll try my best to respond and update this section_

### whisper.cpp CLI cheat-sheet

```
whisper -m ggml-medium.en.bin \
        -f audio.wav \
        --language en \
        --output-dir out/ \
        --output-json transcript.json \
        --output-txt true \
        --beam-size 5
```

> Muesli internally generates a similar command; use it as a reference when debugging. I used it as a reference when debugging, at least.

## License

The source code is released under the **GNU GPLv3 License**.  
Whisper model weights are distributed under their respective licenses (MIT for GGML binaries).  
â€œWhisperâ€ and â€œGPTâ€ are trademarks of their respective owners.

Enjoy your breakfast ğŸ¥£.  
â€“ JBlitzar
